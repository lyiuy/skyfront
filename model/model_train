#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Wed Feb 15 15:28:59 2017@author: Edward.Liu"""import numpy as npimport tensorflow as tfimport pandas as pdfrom sklearn.preprocessing import OneHotEncoderfrom sklearn.metrics import classification_report from sklearn.neural_network import MLPRegressorfrom sklearn.model_selection import cross_val_scorefrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDAfrom sklearn.decomposition import PCAfrom sklearn.preprocessing import normalize, scale, RobustScaler, MaxAbsScaler, StandardScaler, LabelBinarizer, Imputer, OneHotEncoderimport mathimport gcimport reimport osimport datetime#==============================================================================# 读取数据文件#==============================================================================def load_from_csv(path):    columns_name = ['Tim', 'S_ScadaActivePowerControlFlag', 'CI_NacellePosition',                    'CI_RotorSpeed', 'CI_WindSpeed2', 'CI_YawError2',                    'CI_SubPitchPosition1', 'CI_SubPitchPosition2',                    'CI_SubPitchPosition3', 'CI_SubPitchRate1', 'CI_SubPitchRate2',                    'CI_SubPitchRate3', 'CI_SubPitchPrivMotorCurrentBlade1',                    'CI_SubPitchPrivMotorCurrentBlade2', 'CI_SubPitchPrivMotorCurrentBlade3',                    'CI_SubPcsActivePower', 'CI_SubPcsMeasuredGeneratorSpeed',                    'CI_SubPcsMeasuredElectricalTorque', 'CI_SubVibPrivBand1',                    'CI_SubVibPrivBand2', 'CI_SubVibPrivBand3', 'CI_SubVibPrivBand4',                    'CI_SubVibPrivBand5', 'CI_SubVibPrivBand6', 'CI_SubVibPrivBand7',                    'CI_SubVibPrivBand8', 'CI_SubVibPrivBand9', 'CI_SubVibPrivBand10',                    'CI_SubVibPrivBand11', 'CI_SubVibPrivBand12', 'CO_SubPcsTorqueDemand',                    'CI_SubVibNacelleForeAftAcceleration', 'CI_SubVibNacelleSideSideAcceleration',                    'CI_YawActivePower', 'CI_YawGeneratorCurrent', 'D_YawRate',                    'UC_ScadaActivePowerLimit', 'P_ActivePowerLimit', 'S_ControllerState']    df = pd.read_csv(path, names=columns_name, index_col=0, parse_dates=[0])    return df#==============================================================================# 删除无用数据,暂时不用#==============================================================================#def data_delete_process(df):#    df = df[df['CI_SubPitchPosition1'] >= -2]#    df = df[df['CI_SubPitchPosition1'] <= 95]#    df = df[df['CI_SubPitchPosition2'] >= -2]#    df = df[df['CI_SubPitchPosition2'] <= 95]#    df = df[df['CI_SubPitchPosition3'] >= -2]#    df = df[df['CI_SubPitchPosition3'] <= 95]#    df = df.fillna(method = 'bfill',limit = 1)#    df = df[df['S_ControllerState'] <= 38]#    return df#==============================================================================# 读取全部数据训练模型,传入参数为字符串#==============================================================================def read_data_main(number):    file_list = os.listdir('/home/daichuantest02/wind_power/data/data_all/')    pattern = re.compile('\d{1,2}')    mid_df = pd.DataFrame()    for item in file_list:        number_loaded = pattern.findall(item)[1]        if number_loaded == number:            tran_df = load_from_csv('/home/daichuantest02/wind_power/data/data_all/'+item) #       tran_df = data_delete_process(tran_df)            mid_df = mid_df.append(tran_df)            del tran_df            gc.collect()            print('WindPower Generator Data Loading: finish file {0}'.format(item))        else:            pass    return mid_df #==============================================================================# 生成训练batch化需要的时间列表及对数据框的切分#==============================================================================def gen_date_range(df):    time_start = df.index[0]    time_end = df.index[-1]    delta_days = (time_end - time_start).days    date_list = []    for i in range(delta_days+1):        date_list.append([time_start+datetime.timedelta(i),time_start+datetime.timedelta(i+1)])    return date_list    # ==============================================================================# 为读取的数据添加是否处于故障的标签# ==============================================================================def give_broken_label(df, date_start=None, date_end=None):    if date_start == None and date_end == None:        df['label'] = 0        return df    else:              df.loc[:date_start, 'label'] = 0        df.loc[date_start:date_end, 'label'] = 1        df.loc[date_end:, 'label'] = 0    return df.loc[:date_start, :], df.loc[date_start:date_end, :], df.loc[date_end:, :]# ==============================================================================#     数据切片# ==============================================================================def get_data_slice(item):    df_1, df_2, df_3 = give_broken_label(globals()[item[0]], item[1], item[2])    return df_1, df_2, df_3     # ==============================================================================#     将数据切片,分解为故障和正常的batch,为了保证每个batch的size一致,拟采用发现故障前5天的数据(定检)# 作为故障数据,其他同时期的数据作为正常数据进行训练。因为数据存储存在缺失的情况，因此为了保证batch一致，# 需对数据切分时填入容错机制，以每天的数据作为batch进行RNN训练# ==============================================================================   BROKEN_LIST = [['df_sec_2', None, None],               ['df_sec_10', None, None],               ['df_sec_15', None, None],               ['df_sec_22', None, None],               ['df_sec_23', None, None]               ]                                      GOOD_VAR_LIST=['df_sec_2', 'df_sec_10', 'df_sec_15', 'df_sec_22', 'df_sec_23']BAD_VAR_LIST = ['df_sec_1_bad', 'df_sec_3_bad', 'df_sec_20_bad', 'df_sec_25_bad', 'df_sec_25_p2_bad']feature_list = ['CI_NacellePosition', 'CI_RotorSpeed', 'CI_WindSpeed2', 'CI_YawError2','CI_SubPcsMeasuredGeneratorSpeed',                'CI_SubVibPrivBand3', 'CI_SubVibPrivBand6','S_ControllerState','YawTorqueRate', 'PowerLimit','Yaw_State', 'Vibrate']label_list = ['Pit_1','Pit_2','Pit_3']#==============================================================================# 特征工程,预测目标每个叶片的综合状态(变桨系统)#==============================================================================def feature_process(batch_df):    batch_df.loc[:, 'YawTorqueRate'] = (batch_df.loc[:,'CI_SubPcsMeasuredElectricalTorque'] -                                   batch_df.loc[:,'CO_SubPcsTorqueDemand'])/(batch_df.loc[:,'CO_SubPcsTorqueDemand']+1)    batch_df.drop(['CI_SubPcsMeasuredElectricalTorque','CO_SubPcsTorqueDemand'], axis=1, inplace=True)        batch_df.loc[:, 'PowerLimit'] = min(list(batch_df.loc[:, 'UC_ScadaActivePowerLimit']), list(batch_df.loc[:, 'P_ActivePowerLimit']))    batch_df.loc[:, 'Pit_1'] = PCA(n_components=1).fit_transform(batch_df.loc[:,['CI_SubPitchPosition1','CI_SubPitchRate1','CI_SubPitchPrivMotorCurrentBlade1']])    batch_df.loc[:, 'Pit_2'] = PCA(n_components=1).fit_transform(batch_df.loc[:,['CI_SubPitchPosition2','CI_SubPitchRate2','CI_SubPitchPrivMotorCurrentBlade2']])    batch_df.loc[:, 'Pit_3'] = PCA(n_components=1).fit_transform(batch_df.loc[:,['CI_SubPitchPosition3','CI_SubPitchRate3','CI_SubPitchPrivMotorCurrentBlade3']])    batch_df.loc[:, 'Yaw_State'] = PCA(n_components=1).fit_transform(batch_df.loc[:,['CI_YawActivePower','CI_YawGeneratorCurrent','D_YawRate']])    batch_df.drop(['UC_ScadaActivePowerLimit','P_ActivePowerLimit','CI_SubPitchPosition1','CI_SubPitchRate1',                   'CI_SubPitchPrivMotorCurrentBlade1', 'CI_SubPitchPosition2','CI_SubPitchRate2',                   'CI_SubPitchPrivMotorCurrentBlade2', 'CI_SubPitchPosition3','CI_SubPitchRate3',                   'CI_SubPitchPrivMotorCurrentBlade3', 'CI_YawActivePower', 'CI_YawGeneratorCurrent',                   'D_YawRate'], axis=1, inplace=True)    batch_df.loc[:,'Vibrate'] = (abs(batch_df.loc[:, 'CI_SubVibNacelleForeAftAcceleration'])+                            abs(batch_df.loc[:, 'CI_SubVibNacelleSideSideAcceleration']))/2    batch_df.drop(['S_ScadaActivePowerControlFlag','CI_SubVibNacelleForeAftAcceleration', 'CI_SubVibNacelleSideSideAcceleration', 'CI_SubVibPrivBand1',                   'CI_SubVibPrivBand2','CI_SubVibPrivBand4', 'CI_SubVibPrivBand5', 'CI_SubVibPrivBand7', 'CI_SubVibPrivBand8',                   'CI_SubVibPrivBand9','CI_SubVibPrivBand10','CI_SubVibPrivBand11','CI_SubVibPrivBand12'],                    axis=1, inplace=True)    return batch_df#==============================================================================# 针对经过特征工程处理后的batch数据标准化#==============================================================================def gen_normalized_model(df):    rb_input_norm = RobustScaler().fit(df[['CI_WindSpeed2', 'CI_YawError2', 'CI_NacellePosition', 'CI_RotorSpeed']])    mm_output_norm = MaxAbsScaler().fit(df[['Pit_1','Pit_2','Pit_3']])    return rb_input_norm, mm_output_norm    def normal_batch(batch, rb_input_norm, mm_output_norm):    batch[['CI_WindSpeed2', 'CI_YawError2', 'CI_NacellePosition', 'CI_RotorSpeed']] = rb_input_norm.transform(            batch[['CI_WindSpeed2', 'CI_YawError2', 'CI_NacellePosition', 'CI_RotorSpeed']])    batch[['Pit_1','Pit_2','Pit_3']] = mm_output_norm.transform(            batch[['Pit_1','Pit_2','Pit_3']])    return batchdef transfer_to_batch(df, time_start, time_end):    return df.loc[time_start:time_end,:]    def get_batch(df, num_order):    date_list = gen_date_range(df)    df_out = transfer_to_batch(df, date_list[num_order][0],date_list[num_order][1])    return df_outdef batch_to_tensor(batch):    input_array = batch[feature_list]    output_array = batch[label_list]    return input_array, output_array#==============================================================================# Hyper-Para Setting#==============================================================================input_size = len(feature_list)cell_size = 30num_size = 5LR = 0.001n_steps = 1h1_size = 50h2_size = 25h3_size = 15output_size = len(label_list)batch_size = 1000#==============================================================================# RNN Structure#==============================================================================class LSTMRNN():        #initial setting    def __init__(self, n_steps, input_size, output_size, cell_size, h1_size, h2_size, h3_size,num_size, batch_size):        self.n_steps = n_steps        self.input_size = input_size        self.output_size = output_size        self.cell_size = cell_size        self.num_size = num_size        self.h1_size = h1_size        self.h2_size = h2_size        self.h3_size = h3_size        self.batch_size = batch_size                with tf.name_scope('inputs'):            self.xs = tf.placeholder(tf.float32, [None, n_steps, input_size], name='xs')            self.ys = tf.placeholder(tf.float32, [None, n_steps, output_size], name='ys')            self.keep_prob = tf.placeholder(tf.float32, name='keep_prob')                    with tf.name_scope('in_hidden'):            self.add_input_layer()                        with tf.name_scope('LSTM_Cell'):            self.add_cell_layer()                    with tf.name_scope('hidden_1'):            self.add_h1_layer()                    with tf.name_scope('hidden_2'):            self.add_h2_layer()        with tf.name_scope('hidden_3'):            self.add_h3_layer                            with tf.name_scope('out_hidden'):            self.add_output_layer()            with tf.name_scope('cost'):            self.compute_cost()        with tf.name_scope('train'):            self.train_op = tf.train.AdamOptimizer(learning_rate=LR).minimize(self.cost)    def add_input_layer(self):        l_in_x = tf.reshape(self.xs,[-1,self.input_size], name='x_input')        Ws_in = tf.Variable(tf.truncated_normal([self.input_size, self.cell_size], mean=0.01, stddev=0.5))        bs_in = tf.Variable(tf.zeros([self.cell_size,])+0.01)        l_in_y = tf.nn.relu(tf.matmul(l_in_x,Ws_in)+bs_in)        self.l_in_y = tf.reshape(l_in_y,[-1,self.n_steps,self.cell_size],name='cell_input')    def add_cell_layer(self):        lstm_cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(self.cell_size, forget_bias=1.0, state_is_tuple=True), output_keep_prob=self.keep_prob)        lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell]*num_size, state_is_tuple=True)        self.cells_init_state = lstm_cells.zero_state(self.batch_size,dtype=tf.float32)        self.cells_outputs, self.cells_final_state = tf.nn.dynamic_rnn(lstm_cells, self.l_in_y, initial_state=self.cells_init_state, time_major=False)        def add_h1_layer(self):        h1_x = tf.reshape(self.cells_outputs, [-1,self.cell_size])        Ws_h1 = tf.Variable(tf.truncated_normal([self.cell_size, self.h1_size], mean=0.01, stddev=0.5))        bs_h1 = tf.Variable(tf.zeros([self.h1_size,])+0.01)        self.h1_y = tf.nn.relu(tf.matmul(h1_x,Ws_h1)+bs_h1)    def add_h2_layer(self):        h2_x = tf.reshape(self.h1_y, [-1,self.h1_size])        Ws_h2 = tf.Variable(tf.truncated_normal([self.h1_size, self.h2_size], mean=0.01, stddev=0.5))        bs_h2 = tf.Variable(tf.zeros([self.h2_size,])+0.01)        self.h2_y = tf.nn.relu(tf.matmul(h2_x,Ws_h2)+bs_h2)    def add_h3_layer(self):        h3_x = tf.reshape(self.h2_y, [-1,self.h2_size])        Ws_h3 = tf.Variable(tf.truncated_normal([self.h2_size, self.h3_size], mean=0.01, stddev=0.5))        bs_h3 = tf.Variable(tf.zeros([self.h3_size,])+0.01)        self.h3_y = tf.nn.relu(tf.matmul(h3_x,Ws_h3)+bs_h3)                    def add_output_layer(self):        l_out_x = tf.reshape(self.h3_y,[-1,self.h3_size],name = 'y_input')        Ws_out = tf.Variable(tf.truncated_normal([self.h3_size, self.output_size], mean=0.01, stddev=0.5))        bs_out = tf.Variable(tf.zeros([self.output_size,]))        self.pred = tf.matmul(l_out_x,Ws_out)+bs_out    def compute_cost(self):        self.cost = tf.div(tf.reduce_sum(tf.square(tf.subtract(tf.reshape(self.pred,[-1], name='reshape_pred'),                                                               tf.reshape(self.ys,[-1], name='reshape_target')))), self.batch_size)        def train_well_network():    print('----------> 开始读取数据！')    generator_list = ['2','10','15','22','23']    for number in generator_list:        globals()['df_sec_'+str(number)] = read_data_main(number)        for item in BROKEN_LIST:            if item[0] == 'df_sec_'+str(number):                if item[1] == None and item[2] == None:                    globals()[item[0]] = give_broken_label(globals()[item[0]])                    print('----------> 特征工程开始处理该批数据！')                    globals()[item[0]] = feature_process(globals()[item[0]])                    rb_input_norm, mm_output_norm = gen_normalized_model(globals()[item[0]])                    globals()[item[0]] = normal_batch(globals()[item[0]],rb_input_norm, mm_output_norm)                else:                    globals()[item[0]+'_p1'], globals()[item[0]+'_bad'], globals()[item[0]+'_p2'] = get_data_slice(item)                    print('----------> 特征工程开始处理该批数据！')                    for sth in [item[0]+'_p1', item[0]+'_bad', item[0]+'_p2']:                        globals()[sth] = feature_process(globals()[sth])                        rb_input_norm, mm_output_norm = gen_normalized_model(globals()[sth])                        globals()[sth] = normal_batch(globals()[sth], rb_input_norm, mm_output_norm)                    del globals()[item[0]]                    gc.collect()     # globals()['df_sec_25_p2_p1'], globals()['df_sec_25_p2_bad'], globals()['df_sec_25_p2_p2'] = get_data_slice(BROKEN_LIST[-1])    # del globals()['df_sec_25_p2']    # gc.collect()    print('--------->特征工程处理完毕，开始训练！')    model = LSTMRNN(n_steps, input_size, output_size, cell_size, h1_size, h2_size, h3_size, num_size, batch_size)    print('----------> LSTM模型架构完毕，训练正常运行模型！')    saver = tf.train.Saver()    with tf.Session() as sess:        init_op = tf.global_variables_initializer()        sess.run(init_op)        with tf.variable_scope('scope', reuse=True):#            saver.restore(sess, '/home/daichuantest02/wind_power/model_para/good_log')            max_epoch = 20            epoch = 0            while epoch < max_epoch:                for sth in GOOD_VAR_LIST:                    print('----------> 开始处理数据表：{}'.format(sth))                    data = globals()[sth]                    xs_input_total, ys_input_total = batch_to_tensor(data)                    START = 0                    STEP = 1000                    for i in range(int(math.floor(xs_input_total.shape[0]/1000))):                        if i == 0:                            xs_input=xs_input_total.iloc[0:1000,]                            ys_input=ys_input_total.iloc[0:1000,]                            if xs_input[xs_input['S_ControllerState'] >= 38].shape[0] >= xs_input.shape[0]*0.5:                                START += STEP                                next;                            else:                                xs_input,ys_input = np.array(xs_input, dtype='float32'), np.array(ys_input, dtype='float32')                                feed_dict_train = {model.xs:xs_input.reshape([-1,1,input_size]), model.ys:ys_input.reshape([-1,1,output_size]),                                               model.keep_prob: 0.6}                                START += STEP                        else:                            xs_input=xs_input_total.iloc[START:START+STEP,]                            ys_input=ys_input_total.iloc[START:START+STEP,]                            if xs_input[xs_input['S_ControllerState'] >= 38].shape[0] >= xs_input.shape[0]*0.5:                                START += STEP                                next;                            else:                                    xs_input,ys_input = np.array(xs_input, dtype='float32'), np.array(ys_input, dtype='float32')                                feed_dict_train = {model.xs:xs_input.reshape([-1,1,input_size]), model.ys:ys_input.reshape([-1,1,output_size]),                                               model.keep_prob: 0.6, model.cells_init_state:model.state}                                START += STEP                         _, cost, model.state = sess.run(                                [model.train_op, model.cost, model.cells_final_state], feed_dict=feed_dict_train)                        if i % 50 == 0:                            print(("-->中间结果： data:{0}, epoch: {1}, batch: {2}, cost: {3}".format(sth, epoch+1, i, round(cost*10000,2))))                epoch += 1                saver.save(sess, '/home/daichuantest02/wind_power/model_para_good/good_log')            print('----------->Good Samples Train process has completed!<------------------') def train_bad_network():    print('----------> 开始读取数据！')    generator_list = ['1','3','20','25']    for number in generator_list:        globals()['df_sec_'+str(number)] = read_data_main(number)        for item in BROKEN_LIST:            if item[0] == 'df_sec_'+str(number):                if item[1] == None and item[2] == None:                    globals()[item[0]] = give_broken_label(globals()[item[0]])                    print('----------> 特征工程开始处理该批数据！')                    globals()[item[0]] = feature_process(globals()[item[0]])                    rb_input_norm, mm_output_norm = gen_normalized_model(globals()[item[0]])                    globals()[item[0]] = normal_batch(globals()[item[0]],rb_input_norm, mm_output_norm)                else:                    globals()[item[0]+'_p1'], globals()[item[0]+'_bad'], globals()[item[0]+'_p2'] = get_data_slice(item)                    print('----------> 特征工程开始处理该批数据！')                    for sth in [item[0]+'_p1', item[0]+'_bad', item[0]+'_p2']:                        globals()[sth] = give_broken_label(globals()[sth])                        globals()[sth] = feature_process(globals()[sth])                        rb_input_norm, mm_output_norm = gen_normalized_model(globals()[sth])                        globals()[sth] = normal_batch(globals()[sth],rb_input_norm, mm_output_norm)                    del globals()[item[0]]                    gc.collect()    globals()['df_sec_25_p2_p1'], globals()['df_sec_25_p2_bad'], globals()['df_sec_25_p2_p2'] = get_data_slice(BROKEN_LIST[-1])    del globals()['df_sec_25_p2']     print('----------> 特征工程处理完毕，开始训练！')                 gc.collect()    model = LSTMRNN(n_steps, input_size, output_size, cell_size, h1_size, h2_size, h3_size, num_size, batch_size)    print('----------> LSTM模型架构完毕，训练故障运行模型！')    saver = tf.train.Saver()    with tf.Session() as sess:        init_op = tf.global_variables_initializer()        sess.run(init_op)        with tf.variable_scope('scope', reuse=True):                        max_epoch = 100            epoch = 0            while epoch <= max_epoch:                for sth in BAD_VAR_LIST:                    print('----------> 开始处理数据表：{}'.format(sth))                    data = globals()[sth]                    xs_input_total, ys_input_total = batch_to_tensor(data)                    START = 0                    STEP = 1000                    for i in range(math.floor(xs_input_total.shape[0]/1000)):                        if i == 0:                            xs_input=xs_input_total.iloc[0:1000,]                            ys_input=ys_input_total.iloc[0:1000,]                            if xs_input[xs_input['S_ControllerState'] >= 38].shape[0] >= xs_input.shape[0]*0.5:                                START += STEP                                next;                            else:                                xs_input,ys_input = np.array(xs_input, dtype='float32'), np.array(ys_input, dtype='float32')                                feed_dict_train = {model.xs:xs_input.reshape([-1,1,input_size]), model.ys:ys_input.reshape([-1,1,output_size]),                                               model.keep_prob: 0.8}                                START += STEP                        else:                            xs_input=xs_input_total.iloc[START:START+STEP,]                            ys_input=ys_input_total.iloc[START:START+STEP,]                            if xs_input[xs_input['S_ControllerState'] >= 38].shape[0] >= xs_input.shape[0]*0.5:                                START += STEP                                next;                            else:                                    xs_input,ys_input = np.array(xs_input, dtype='float32'), np.array(ys_input, dtype='float32')                                feed_dict_train = {model.xs:xs_input.reshape([-1,1,input_size]), model.ys:ys_input.reshape([-1,1,output_size]),                                               model.keep_prob: 0.8, model.cells_init_state:model.state}                                START += STEP                         _, cost, model.state = sess.run(                                [model.train_op, model.cost, model.cells_final_state], feed_dict=feed_dict_train)                        if i % 50 == 0:                            print(("-->中间结果： data:{0}, epoch: {1}, batch: {2}, cost: {3}".format(sth, epoch+1, i, round(cost*10000,2))))                epoch += 1                saver.save(sess, '/home/daichuantest02/wind_power/model_para_bad/bad_log')            print('----------------->Bad Samples Train process has completed!<-------------------')             if __name__ == '__main__':    print('---------RNN训练中------------')    train_well_network()#    train_bad_network()    
